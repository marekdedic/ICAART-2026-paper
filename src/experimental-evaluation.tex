\section{\uppercase{Experimental evaluation of the Cross-RF method}}

In order to evaluate the proposed Cross-RF method, we conducted experiments on the same datasets as described in Section~\ref{sec:benchmark}, using the same evaluation routine and search space.

\subsection{Meta-model architecture}

The meta-model used in the Cross-RF method is a Random Forest regressor \cite{breiman_random_2001}, implemented using the \texttt{RandomForestRegressor} class from the \texttt{scikit-learn} library \cite{pedregosa_scikit-learn_2011}. The Random Forest was configured with 100 trees, and other hyper-parameters were set to their default values, except for the maximum number of features to consider for each split, which was set to \( 30\% \) of the total number of features.

Several small implementation details are worth mentioning. First, in each step of the optimisation, all of the already evaluated configurations from \( \mathcal{H} \) are excluded from the set of candidate configurations \( \tilde{\Lambda} \), so that the same configuration isn't needlessly re-evaluated. Second, all categorical features are one-hot encoded before being passed to the Random Forest model. Finally, in all our experiments, we used the F1-score as the performance metric \( \rho \) to be optimised.

\subsection{Results and Analysis}
\todo[inline]{Results}
