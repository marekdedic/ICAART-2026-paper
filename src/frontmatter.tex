\title{Benchmarking and Transfer Learning for Hyperparameter Optimization of Graph Neural Networks}

\author{\authorname{Marek Dědič\sup{1, 2}\orcidAuthor{0000-0003-1021-8428} and Michal Bělohlávek\sup{1, 2}}
\affiliation{\sup{1}Czech Technical University in Prague, Trojanova 13, Praha 2, Czechia}
\affiliation{\sup{2}Cisco Systems, Praha, Czechia}
\email{marek@dedic.eu, mbelohla@cisco.com}
}

\keywords{Graph Neural Networks, Hyperparameter Optimization, Meta-Learning}

\abstract{%
	\todo[inline]{Hide authors}
	Graph Neural Networks (GNNs) have become essential for machine learning on graph-structured data. The performance of these models, however, is critically dependent on effective hyperparameter optimization (HPO), as choices in learning rate, hidden dimensions, and sampling strategies can lead to significant performance variations. Despite extensive benchmarking of HPO algorithms for traditional tabular, image, and text data, comprehensive evaluations for graph learning tasks remain limited. This paper addresses this gap by presenting an extensive benchmark of various HPO strategies for GNNs, comparing simple methods like random search against more sophisticated sequential model-based optimization (SMBO) techniques, including Bayesian Optimization (BO) and Tree-structured Parzen Estimators (TPE). Furthermore, we explore the use of meta-learning for transfer learning, investigating its potential to accelerate HPO on new tasks by leveraging knowledge from previously completed optimization runs. Our results provide a comparative guide for practitioners and demonstrate the viability of transfer learning to improve the efficiency of GNN hyperparameter tuning.
}

\onecolumn \maketitle \normalsize \setcounter{footnote}{0} \vfill
